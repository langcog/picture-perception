{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f77891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from joblib import Parallel, delayed\n",
    "from numpy.random import Generator, PCG64\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6402cad1",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182e99b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoa_df = pd.read_csv(\"../data/word_age_of_acquisition.csv\")\n",
    "aoa_df = aoa_df.replace({\"comb (object)\": \"comb\"})\n",
    "df = pd.read_csv(\"../data/kisumu_vocab_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a2a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_classification = pd.read_csv(\"../data/word_classification_df.csv\")\n",
    "word_classification['Target'] = word_classification['Target'].apply(lambda w : w.lower())\n",
    "word_classification['Near Distractor'] = word_classification['Near Distractor'].apply(lambda w : w.lower())\n",
    "word_classification['Random 1'] = word_classification['Random 1'].apply(lambda w : w.lower())\n",
    "word_classification['Random 2'] = word_classification['Random 2'].apply(lambda w : w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf32a31a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/Kisumu 2024 Vocabulary - Vocab.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gl/tf1l1j554s186d_crpz71bw80000gn/T/ipykernel_44734/4276669213.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0msubject_responses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/Kisumu 2024 Vocabulary - Vocab.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Subject Number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mall_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_classification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"target_word\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Target\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mall_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maoa_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'target_word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/Kisumu 2024 Vocabulary - Vocab.csv'"
     ]
    }
   ],
   "source": [
    "def find_word(r):\n",
    "    target = r['target_word'].title()\n",
    "    word_response = subject_responses[\n",
    "        (subject_responses[\"Subject Number\"] == r[\"child\"])\n",
    "    ].iloc[0][target]\n",
    "\n",
    "    return word_response.lower()\n",
    "\n",
    "def classify_response(r):\n",
    "    res = r['response']\n",
    "    if res == r['Target']:\n",
    "        return 'Target'\n",
    "    elif res == r['Near Distractor']:\n",
    "        return 'Near Distractor'\n",
    "    elif res == r['Random 1'] or r['Random 2']:\n",
    "        return 'Random'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "subject_responses = pd.read_csv(\"../data/Kisumu 2024 Vocabulary - Vocab.csv\").dropna(subset=\"Subject Number\")\n",
    "all_df = pd.merge(df, word_classification, left_on=\"target_word\", right_on=\"Target\", how=\"left\")\n",
    "all_df = pd.merge(all_df, aoa_df, on='target_word', how='left')\n",
    "all_df['response'] = all_df.apply(find_word, axis=1)\n",
    "all_df['response_type'] = all_df.apply(classify_response, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2147f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a4aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0b0af7f",
   "metadata": {},
   "source": [
    "# Error Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04f9c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = all_df.copy()\n",
    "filtered_df = filtered_df[filtered_df['accuracy'] == 0]\n",
    "filtered_df['is_near_distractor'] = (filtered_df['response_type'] == 'Near Distractor').astype(int)\n",
    "filtered_df['is_random'] = (filtered_df['response_type'] == 'Random').astype(int)\n",
    "filtered_df['condition'] = filtered_df['condition'].replace({\n",
    "    'bw': 'black_white',\n",
    "    'obj': 'object',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ceac192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(\n",
    "        data,\n",
    "        measure,\n",
    "        id_col,\n",
    "        n_iterations=10000,\n",
    "        statistic=np.mean):\n",
    "    \n",
    "    items = list(data[id_col].unique())\n",
    "    n_size = len(items)\n",
    "    df = data.copy()\n",
    "\n",
    "    def bootstrap_iteration(data, chosen_items):\n",
    "        filter_df = data[data[id_col].isin(chosen_items)] # Filter based on chosen questions\n",
    "        bs_mean = statistic(filter_df[measure]) \n",
    "        return (bs_mean, list(chosen_items))\n",
    "\n",
    "    qset_means = Parallel(n_jobs=-1)(\n",
    "        delayed(bootstrap_iteration)(\n",
    "            df.copy(),\n",
    "            rng.choice(items, n_size,  replace=True)\n",
    "        ) for _ in range(n_iterations)\n",
    "    )\n",
    "    \n",
    "    means = []\n",
    "    qs_used = []\n",
    "    means = [bs_mean for bs_mean, chosen_qs in qset_means]\n",
    " \n",
    "    # 95% confidence interval\n",
    "    lower = np.percentile(means, 2.5)\n",
    "    upper = np.percentile(means, 97.5)\n",
    "    \n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "def create_confidence_interval_df(\n",
    "    data,\n",
    "    measure, \n",
    "    id_col,\n",
    "    condition_col,\n",
    "    statistic=np.mean\n",
    "):\n",
    "    data_list = []\n",
    "\n",
    "    for condition in data[condition_col].unique():\n",
    "        condition_data = data[data[condition_col] == condition]\n",
    "\n",
    "        lower, upper = bootstrap_ci(condition_data, measure=measure, statistic=statistic, id_col=id_col)\n",
    "\n",
    "        data_list.append({\n",
    "            \"condition\": condition,\n",
    "            \"ci_upper\": upper, \n",
    "            \"ci_lower\": lower,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4cf0eb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_dfs(df, measure):\n",
    "    agg_data = df.groupby(['condition']).agg(\n",
    "        mean_prop=(measure, 'mean')\n",
    "    ).reset_index()\n",
    "    \n",
    "    word_level_data = df.groupby(['condition', 'target_word']).agg(\n",
    "        mean_prop=(measure, 'mean')\n",
    "    ).reset_index()\n",
    "    word_level_data['item_id'] = word_level_data['condition'] + word_level_data['target_word']\n",
    "    \n",
    "    ci_df = create_confidence_interval_df(\n",
    "        data=df,\n",
    "        measure=measure,\n",
    "        id_col='target_word',\n",
    "        condition_col='condition'\n",
    "    )\n",
    "\n",
    "    error_df = pd.merge(agg_data, ci_df, on=['condition'])\n",
    "\n",
    "    return error_df, word_level_data\n",
    "\n",
    "error_dfs, item_dfs = get_error_dfs(\n",
    "    filtered_df, \n",
    "    measure='is_random'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b13655f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-4c7316ea21004e9eada841aca2fbb438.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-4c7316ea21004e9eada841aca2fbb438.vega-embed details,\n",
       "  #altair-viz-4c7316ea21004e9eada841aca2fbb438.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-4c7316ea21004e9eada841aca2fbb438\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4c7316ea21004e9eada841aca2fbb438\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4c7316ea21004e9eada841aca2fbb438\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-01e047d3a2b32a51620efce3a8ca4517\"}, \"mark\": {\"type\": \"point\", \"filled\": true, \"opacity\": 1, \"size\": 75}, \"encoding\": {\"color\": {\"field\": \"condition\", \"type\": \"nominal\"}, \"x\": {\"field\": \"condition\", \"scale\": {\"domain\": [\"black_white\", \"cartoon\", \"photo\", \"object\"]}, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_prop\", \"scale\": {\"domain\": [0, 1]}, \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-61e613465f2c0db47b942b44a0f4d593\"}, \"mark\": {\"type\": \"circle\", \"opacity\": 0.5, \"size\": 16}, \"encoding\": {\"color\": {\"field\": \"condition\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"condition\", \"title\": null, \"type\": \"nominal\"}, \"xOffset\": {\"field\": \"jitter\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_prop\", \"scale\": {\"domain\": [0, 1]}, \"type\": \"quantitative\"}}, \"transform\": [{\"calculate\": \"sqrt(-2*log(random()))*cos(2*PI*random())\", \"as\": \"jitter\"}]}, {\"data\": {\"name\": \"data-01e047d3a2b32a51620efce3a8ca4517\"}, \"mark\": {\"type\": \"errorbar\"}, \"encoding\": {\"color\": {\"field\": \"condition\", \"legend\": null, \"type\": \"nominal\"}, \"strokeWidth\": {\"value\": 2}, \"x\": {\"field\": \"condition\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"ci_upper\", \"title\": \"Proportion Far Distractors\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"ci_lower\"}}}, {\"data\": {\"name\": \"data-01e047d3a2b32a51620efce3a8ca4517\"}, \"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeDash\": [5, 10]}, \"encoding\": {\"opacity\": {\"value\": 0.5}, \"y\": {\"datum\": 0.66}}}], \"title\": \"Proportion of Incorrect Responses\", \"width\": 150, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-01e047d3a2b32a51620efce3a8ca4517\": [{\"condition\": \"black_white\", \"mean_prop\": 0.7333333333333333, \"ci_upper\": 0.8414634146341463, \"ci_lower\": 0.5890372907153729}, {\"condition\": \"cartoon\", \"mean_prop\": 0.6687898089171974, \"ci_upper\": 0.7777777777777778, \"ci_lower\": 0.5}, {\"condition\": \"object\", \"mean_prop\": 0.5333333333333333, \"ci_upper\": 0.6842105263157895, \"ci_lower\": 0.34039703647416414}, {\"condition\": \"photo\", \"mean_prop\": 0.7133333333333334, \"ci_upper\": 0.8, \"ci_lower\": 0.5509948979591837}], \"data-61e613465f2c0db47b942b44a0f4d593\": [{\"condition\": \"black_white\", \"target_word\": \"ball\", \"mean_prop\": 0.6666666666666666, \"item_id\": \"black_whiteball\"}, {\"condition\": \"black_white\", \"target_word\": \"book\", \"mean_prop\": 0.2222222222222222, \"item_id\": \"black_whitebook\"}, {\"condition\": \"black_white\", \"target_word\": \"bowl\", \"mean_prop\": 0.45454545454545453, \"item_id\": \"black_whitebowl\"}, {\"condition\": \"black_white\", \"target_word\": \"box\", \"mean_prop\": 0.6666666666666666, \"item_id\": \"black_whitebox\"}, {\"condition\": \"black_white\", \"target_word\": \"button\", \"mean_prop\": 0.9259259259259259, \"item_id\": \"black_whitebutton\"}, {\"condition\": \"black_white\", \"target_word\": \"chalk\", \"mean_prop\": 0.76, \"item_id\": \"black_whitechalk\"}, {\"condition\": \"black_white\", \"target_word\": \"comb\", \"mean_prop\": 1.0, \"item_id\": \"black_whitecomb\"}, {\"condition\": \"black_white\", \"target_word\": \"cup\", \"mean_prop\": 0.0, \"item_id\": \"black_whitecup\"}, {\"condition\": \"black_white\", \"target_word\": \"fork\", \"mean_prop\": 0.9166666666666666, \"item_id\": \"black_whitefork\"}, {\"condition\": \"black_white\", \"target_word\": \"pencil\", \"mean_prop\": 1.0, \"item_id\": \"black_whitepencil\"}, {\"condition\": \"black_white\", \"target_word\": \"scissors\", \"mean_prop\": 0.0, \"item_id\": \"black_whitescissors\"}, {\"condition\": \"black_white\", \"target_word\": \"shoe\", \"mean_prop\": 0.0, \"item_id\": \"black_whiteshoe\"}, {\"condition\": \"black_white\", \"target_word\": \"shorts\", \"mean_prop\": 0.9230769230769231, \"item_id\": \"black_whiteshorts\"}, {\"condition\": \"black_white\", \"target_word\": \"sweater\", \"mean_prop\": 1.0, \"item_id\": \"black_whitesweater\"}, {\"condition\": \"black_white\", \"target_word\": \"toothbrush\", \"mean_prop\": 0.8823529411764706, \"item_id\": \"black_whitetoothbrush\"}, {\"condition\": \"cartoon\", \"target_word\": \"book\", \"mean_prop\": 0.0, \"item_id\": \"cartoonbook\"}, {\"condition\": \"cartoon\", \"target_word\": \"bowl\", \"mean_prop\": 0.3333333333333333, \"item_id\": \"cartoonbowl\"}, {\"condition\": \"cartoon\", \"target_word\": \"box\", \"mean_prop\": 0.2857142857142857, \"item_id\": \"cartoonbox\"}, {\"condition\": \"cartoon\", \"target_word\": \"button\", \"mean_prop\": 0.85, \"item_id\": \"cartoonbutton\"}, {\"condition\": \"cartoon\", \"target_word\": \"chalk\", \"mean_prop\": 0.7692307692307693, \"item_id\": \"cartoonchalk\"}, {\"condition\": \"cartoon\", \"target_word\": \"comb\", \"mean_prop\": 1.0, \"item_id\": \"cartooncomb\"}, {\"condition\": \"cartoon\", \"target_word\": \"cup\", \"mean_prop\": 0.0, \"item_id\": \"cartooncup\"}, {\"condition\": \"cartoon\", \"target_word\": \"fork\", \"mean_prop\": 0.8421052631578947, \"item_id\": \"cartoonfork\"}, {\"condition\": \"cartoon\", \"target_word\": \"pencil\", \"mean_prop\": 0.0, \"item_id\": \"cartoonpencil\"}, {\"condition\": \"cartoon\", \"target_word\": \"shirt\", \"mean_prop\": 1.0, \"item_id\": \"cartoonshirt\"}, {\"condition\": \"cartoon\", \"target_word\": \"shoe\", \"mean_prop\": 0.2, \"item_id\": \"cartoonshoe\"}, {\"condition\": \"cartoon\", \"target_word\": \"shorts\", \"mean_prop\": 0.9285714285714286, \"item_id\": \"cartoonshorts\"}, {\"condition\": \"cartoon\", \"target_word\": \"sweater\", \"mean_prop\": 0.3333333333333333, \"item_id\": \"cartoonsweater\"}, {\"condition\": \"cartoon\", \"target_word\": \"toothbrush\", \"mean_prop\": 0.8235294117647058, \"item_id\": \"cartoontoothbrush\"}, {\"condition\": \"object\", \"target_word\": \"ball\", \"mean_prop\": 0.0, \"item_id\": \"objectball\"}, {\"condition\": \"object\", \"target_word\": \"book\", \"mean_prop\": 0.5, \"item_id\": \"objectbook\"}, {\"condition\": \"object\", \"target_word\": \"bowl\", \"mean_prop\": 0.125, \"item_id\": \"objectbowl\"}, {\"condition\": \"object\", \"target_word\": \"box\", \"mean_prop\": 0.0, \"item_id\": \"objectbox\"}, {\"condition\": \"object\", \"target_word\": \"button\", \"mean_prop\": 0.4, \"item_id\": \"objectbutton\"}, {\"condition\": \"object\", \"target_word\": \"chalk\", \"mean_prop\": 0.5, \"item_id\": \"objectchalk\"}, {\"condition\": \"object\", \"target_word\": \"comb\", \"mean_prop\": 1.0, \"item_id\": \"objectcomb\"}, {\"condition\": \"object\", \"target_word\": \"cup\", \"mean_prop\": 0.0, \"item_id\": \"objectcup\"}, {\"condition\": \"object\", \"target_word\": \"fork\", \"mean_prop\": 0.7727272727272727, \"item_id\": \"objectfork\"}, {\"condition\": \"object\", \"target_word\": \"scissors\", \"mean_prop\": 0.0, \"item_id\": \"objectscissors\"}, {\"condition\": \"object\", \"target_word\": \"shirt\", \"mean_prop\": 0.8333333333333334, \"item_id\": \"objectshirt\"}, {\"condition\": \"object\", \"target_word\": \"shorts\", \"mean_prop\": 0.9545454545454546, \"item_id\": \"objectshorts\"}, {\"condition\": \"object\", \"target_word\": \"sweater\", \"mean_prop\": 0.0, \"item_id\": \"objectsweater\"}, {\"condition\": \"object\", \"target_word\": \"toothbrush\", \"mean_prop\": 0.7, \"item_id\": \"objecttoothbrush\"}, {\"condition\": \"photo\", \"target_word\": \"book\", \"mean_prop\": 0.0, \"item_id\": \"photobook\"}, {\"condition\": \"photo\", \"target_word\": \"bowl\", \"mean_prop\": 0.2857142857142857, \"item_id\": \"photobowl\"}, {\"condition\": \"photo\", \"target_word\": \"box\", \"mean_prop\": 0.4, \"item_id\": \"photobox\"}, {\"condition\": \"photo\", \"target_word\": \"button\", \"mean_prop\": 0.75, \"item_id\": \"photobutton\"}, {\"condition\": \"photo\", \"target_word\": \"chalk\", \"mean_prop\": 0.6842105263157895, \"item_id\": \"photochalk\"}, {\"condition\": \"photo\", \"target_word\": \"comb\", \"mean_prop\": 0.8333333333333334, \"item_id\": \"photocomb\"}, {\"condition\": \"photo\", \"target_word\": \"cup\", \"mean_prop\": 0.25, \"item_id\": \"photocup\"}, {\"condition\": \"photo\", \"target_word\": \"fork\", \"mean_prop\": 0.9, \"item_id\": \"photofork\"}, {\"condition\": \"photo\", \"target_word\": \"scissors\", \"mean_prop\": 0.0, \"item_id\": \"photoscissors\"}, {\"condition\": \"photo\", \"target_word\": \"shirt\", \"mean_prop\": 1.0, \"item_id\": \"photoshirt\"}, {\"condition\": \"photo\", \"target_word\": \"shoe\", \"mean_prop\": 0.0, \"item_id\": \"photoshoe\"}, {\"condition\": \"photo\", \"target_word\": \"shorts\", \"mean_prop\": 0.9666666666666667, \"item_id\": \"photoshorts\"}, {\"condition\": \"photo\", \"target_word\": \"sweater\", \"mean_prop\": 0.5, \"item_id\": \"photosweater\"}, {\"condition\": \"photo\", \"target_word\": \"toothbrush\", \"mean_prop\": 0.8181818181818182, \"item_id\": \"phototoothbrush\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_error_plot(error_df, item_level_df):\n",
    "    ci_plot = alt.Chart(error_df).mark_errorbar().encode(\n",
    "        x=alt.X(\"condition:N\", title=None),\n",
    "        y=alt.Y(\"ci_upper\", title=\"Proportion Far Distractors\"),\n",
    "        y2=alt.Y2(\"ci_lower\"),\n",
    "        strokeWidth=alt.value(2),\n",
    "        color=alt.Color('condition').legend(None)\n",
    "    )\n",
    "\n",
    "    mean_points = alt.Chart(error_df).mark_point(filled=True, size=75, opacity=1).encode(\n",
    "        x=alt.X('condition:N', scale=alt.Scale(domain=[\"black_white\", 'cartoon', 'photo', 'object'])),\n",
    "        y=alt.Y('mean_prop:Q', scale=alt.Scale(domain=[0,1])),\n",
    "        color='condition:N'\n",
    "    )\n",
    "    \n",
    "    scatter_plot = alt.Chart(item_level_df).mark_circle(size=16,opacity=0.5).encode(\n",
    "        x=alt.X(\"condition:N\", title=None),\n",
    "        y=alt.Y(\"mean_prop:Q\", scale=alt.Scale(domain=[0,1])),\n",
    "        xOffset=\"jitter:Q\",\n",
    "        color=alt.Color('condition:N').legend(None),\n",
    "    ).transform_calculate(\n",
    "        jitter=\"sqrt(-2*log(random()))*cos(2*PI*random())\" \n",
    "    )\n",
    "    \n",
    "    dashed_line = alt.Chart(error_df).mark_rule(strokeDash=[5, 10], color='black').encode(\n",
    "        y=alt.datum(0.66),\n",
    "        opacity=alt.value(0.5)\n",
    "    )\n",
    "    \n",
    "    return mean_points + scatter_plot + ci_plot + dashed_line\n",
    "\n",
    "plot = create_error_plot(error_dfs, item_dfs)\n",
    "plot = plot.properties(width=150, title=\"Proportion of Incorrect Responses\")\n",
    "plot.save(\"proportion_incorrect_plot.pdf\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5cafcf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>mean_prop</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>ci_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>black_white</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.589037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cartoon</td>\n",
       "      <td>0.668790</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>object</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.340397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>photo</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.550995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     condition  mean_prop  ci_upper  ci_lower\n",
       "0  black_white   0.733333  0.841463  0.589037\n",
       "1      cartoon   0.668790  0.777778  0.500000\n",
       "2       object   0.533333  0.684211  0.340397\n",
       "3        photo   0.713333  0.800000  0.550995"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b2bbe8",
   "metadata": {},
   "source": [
    "# Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36b82413",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_selection_df = all_df.copy()\n",
    "all_selection_df = all_selection_df[all_selection_df['accuracy'] == 0]\n",
    "all_selection_df['is_near_distractor'] = (all_selection_df['response_type'] == 'Near Distractor').astype(int)\n",
    "all_selection_df['is_random'] = (all_selection_df['response_type'] == 'Random').astype(int)\n",
    "all_selection_df = all_selection_df[['child', 'condition', 'age', 'target_word', 'accuracy', 'response_type', 'is_near_distractor', 'is_random']]\n",
    "all_selection_df.to_csv(\"error_trials_only.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5364633a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "354b149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77126c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Please select a CRAN mirror for use in this session ---\n",
      "Secure CRAN mirrors \n",
      "\n",
      " 1: 0-Cloud [https]\n",
      " 2: Australia (Canberra) [https]\n",
      " 3: Australia (Melbourne 1) [https]\n",
      " 4: Australia (Melbourne 2) [https]\n",
      " 5: Austria (Wien 1) [https]\n",
      " 6: Belgium (Brussels) [https]\n",
      " 7: Brazil (PR) [https]\n",
      " 8: Brazil (SP 1) [https]\n",
      " 9: Brazil (SP 2) [https]\n",
      "10: Bulgaria [https]\n",
      "11: Canada (MB) [https]\n",
      "12: Canada (ON 1) [https]\n",
      "13: Canada (ON 2) [https]\n",
      "14: Chile (Santiago) [https]\n",
      "15: China (Beijing 2) [https]\n",
      "16: China (Beijing 3) [https]\n",
      "17: China (Hefei) [https]\n",
      "18: China (Hong Kong) [https]\n",
      "19: China (Jinan) [https]\n",
      "20: China (Lanzhou) [https]\n",
      "21: China (Nanjing) [https]\n",
      "22: China (Shanghai 2) [https]\n",
      "23: China (Shenzhen) [https]\n",
      "24: China (Wuhan) [https]\n",
      "25: Colombia (Cali) [https]\n",
      "26: Costa Rica [https]\n",
      "27: Cyprus [https]\n",
      "28: Czech Republic [https]\n",
      "29: Denmark [https]\n",
      "30: East Asia [https]\n",
      "31: Ecuador (Cuenca) [https]\n",
      "32: France (Lyon 1) [https]\n",
      "33: France (Lyon 2) [https]\n",
      "34: France (Marseille) [https]\n",
      "35: France (Paris 1) [https]\n",
      "36: Germany (Erlangen) [https]\n",
      "37: Germany (Göttingen) [https]\n",
      "38: Germany (Leipzig) [https]\n",
      "39: Germany (Münster) [https]\n",
      "40: Greece [https]\n",
      "41: Iceland [https]\n",
      "42: India (Bengaluru) [https]\n",
      "43: India (Bhubaneswar) [https]\n",
      "44: Indonesia (Banda Aceh) [https]\n",
      "45: Iran (Mashhad) [https]\n",
      "46: Italy (Milano) [https]\n",
      "47: Italy (Padua) [https]\n",
      "48: Japan (Yonezawa) [https]\n",
      "49: Korea (Gyeongsan-si) [https]\n",
      "50: Mexico (Mexico City) [https]\n",
      "51: Mexico (Texcoco) [https]\n",
      "52: Morocco [https]\n",
      "53: Netherlands (Dronten) [https]\n",
      "54: New Zealand [https]\n",
      "55: South Africa (Johannesburg) [https]\n",
      "56: Spain (A Coruña) [https]\n",
      "57: Spain (Madrid) [https]\n",
      "58: Sweden (Umeå) [https]\n",
      "59: Switzerland (Zurich 1) [https]\n",
      "60: Taiwan (Taipei) [https]\n",
      "61: Turkey (Denizli) [https]\n",
      "62: UK (Bristol) [https]\n",
      "63: UK (London 1) [https]\n",
      "64: USA (IA) [https]\n",
      "65: USA (MI) [https]\n",
      "66: USA (MO) [https]\n",
      "67: USA (OH) [https]\n",
      "68: USA (OR) [https]\n",
      "69: USA (PA 1) [https]\n",
      "70: USA (TN) [https]\n",
      "71: USA (UT) [https]\n",
      "72: United Arab Emirates [https]\n",
      "73: Uruguay [https]\n",
      "74: (other mirrors)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Selection:  68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/v8/3zpbxkws53b3x6m8509jyml80000gn/T//RtmpAhZ5Zf/downloaded_packages\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trying URL 'https://ftp.osuosl.org/pub/cran/bin/macosx/big-sur-arm64/contrib/4.4/lme4_1.1-36.tgz'\n",
       "Content type 'application/x-gzip' length 7079300 bytes (6.8 MB)\n",
       "==================================================\n",
       "downloaded 6.8 MB\n",
       "\n",
       "Loading required package: Matrix\n",
       "In addition: Warning message:\n",
       "In doTryCatch(return(expr), name, parentenv, handler) :\n",
       "  unable to load shared object '/Library/Frameworks/R.framework/Resources/modules//R_X11.so':\n",
       "  dlopen(/Library/Frameworks/R.framework/Resources/modules//R_X11.so, 0x0006): Library not loaded: /opt/X11/lib/libSM.6.dylib\n",
       "  Referenced from: <34C5A480-1AC4-30DF-83C9-30A913FC042E> /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/modules/R_X11.so\n",
       "  Reason: tried: '/opt/X11/lib/libSM.6.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/X11/lib/libSM.6.dylib' (no such file), '/opt/X11/lib/libSM.6.dylib' (no such file), '/usr/local/lib/libSM.6.dylib' (no such file), '/usr/lib/libSM.6.dylib' (no such file, not in dyld cache)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "install.packages(\"lme4\")\n",
    "library(lme4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45578af2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f830a70",
   "metadata": {},
   "source": [
    "The below is implemented in the `picture-perception-error-analysis.Rmd` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8ecbe57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In addition: Warning messages:\n",
       "1: In commonArgs(par, fn, control, environment()) :\n",
       "  maxfun < 10 * length(par)^2 is not recommended.\n",
       "2: In optwrap(optimizer, devfun, start, rho$lower, control = control,  :\n",
       "  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded\n",
       "3: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :\n",
       "  failure to converge in 10000 evaluations\n",
       "4: In optwrap(optimizer, devfun, start, rho$lower, control = control,  :\n",
       "  convergence code 4 from Nelder_Mead: failure to converge in 10000 evaluations\n",
       "5: In checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv,  :\n",
       "  unable to evaluate scaled gradient\n",
       "6: In checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv,  :\n",
       "  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues\n",
       "7: In commonArgs(par, fn, control, environment()) :\n",
       "  maxfun < 10 * length(par)^2 is not recommended.\n",
       "8: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :\n",
       "  failure to converge in 10000 evaluations\n",
       "9: In optwrap(optimizer, devfun, start, rho$lower, control = control,  :\n",
       "  convergence code 4 from Nelder_Mead: failure to converge in 10000 evaluations\n",
       "10: In checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv,  :\n",
       "  Model failed to converge with max|grad| = 0.975978 (tol = 0.002, component 1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i all_selection_df\n",
    "\n",
    "base_model <- glmer(\n",
    "    is_random ~ 1  + (condition | child) + (condition * age | target_word), \n",
    "    data=all_selection_df, \n",
    "    family = \"binomial\"\n",
    ")\n",
    "\n",
    "condition_model <- glmer(\n",
    "    is_random ~ condition * age + (condition | child) + (condition * age | target_word), \n",
    "    data=all_selection_df, \n",
    "    family = \"binomial\"\n",
    ")\n",
    "\n",
    "anova(base_model, condition_model, test = \"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbfce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "base_model <- glmer(\n",
    "    is_random ~ 1  + (condition | child), \n",
    "    data=all_selection_df, \n",
    "    family = \"binomial\"\n",
    ")\n",
    "\n",
    "condition_model <- glmer(\n",
    "    is_random ~ condition + (condition | child), \n",
    "    data=all_selection_df, \n",
    "    family = \"binomial\"\n",
    ")\n",
    "\n",
    "anova(base_model, condition_model, test = \"Chisq\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
